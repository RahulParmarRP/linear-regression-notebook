{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "source": [
    "# Offline Handwriting Recognition using CNN\n",
    "\n",
    "This notebook is the implementation of deep learning models for classify writers based on their writing styles. Dataset used is IAM Handwriting Dataset. Summary of this notebook is also presented on the project [website](https://tejasreddy9.github.io/handwriting_cnn). I've only considered only 50 writers data as that was sufficient in the classification. More might cause overfitting. Each writer is given a set of sentences. Each sentence is taken seperately and prerocessed. \n",
    "\n",
    "## Classification Model\n",
    "\n",
    "I've built this using Keras in Python with TensorFlow as backend. This model is language independent as we dont consider the letters or words in particular, but patches of image size 113x113 are extracted and fit into the model for learning. \n",
    "\n",
    "## Results\n",
    "\n",
    "This model given impressive 94% accuracy on test data.\n",
    "\n",
    "## Dataset\n",
    "[IAM Handwritten Dataset](https://www.kaggle.com/tejasreddy/iam-handwriting-top50)\n",
    "\n",
    "I've uploaded this dataset to kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "### Imports\n",
    "Import these packages to the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "ff03e0be8b022e42a9f1c880c36bf45c21f04402"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1e35d6c6facc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from random import *\n",
    "from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c92d898a98684fe82c0ffb1294f9c93744899c7"
   },
   "source": [
    "These are the forms in the dataset for quick access from manipulation of the file names on each column. Let's create a dictionary with form and writer mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4916eca832ed28a895eca80142ad6c419956a397"
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "# forms = pd.read_csv('../input/iam-handwriting-top50/forms_for_parsing.txt', header=None)\n",
    "# print(forms.head)\n",
    "with open('../input/forms_for_parsing.txt') as f:\n",
    "    for line in f:\n",
    "        key = line.split(' ')[0]\n",
    "        writer = line.split(' ')[1]\n",
    "        d[key] = writer\n",
    "print(len(d.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b53f31b2cba8e74f0870005093e191daf3fa54c5"
   },
   "source": [
    "All file-names list and target-writer names list are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43eb1b4e0c76027ca35a89c7f86e5cdfd65dca69"
   },
   "outputs": [],
   "source": [
    "tmp = []\n",
    "target_list = []\n",
    "\n",
    "path_to_files = os.path.join('../input/data_subset/data_subset', '*')\n",
    "for filename in sorted(glob.glob(path_to_files)):\n",
    "#     print(filename)\n",
    "    tmp.append(filename)\n",
    "    image_name = filename.split('/')[-1]\n",
    "    file, ext = os.path.splitext(image_name)\n",
    "    parts = file.split('-')\n",
    "    form = parts[0] + '-' + parts[1]\n",
    "    for key in d:\n",
    "        if key == form:\n",
    "            target_list.append(str(d[form]))\n",
    "\n",
    "img_files = np.asarray(tmp)\n",
    "img_targets = np.asarray(target_list)\n",
    "print(img_files.shape)\n",
    "print(img_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b80001a82c05277cbf74b0a92f0dd87f7926cab1"
   },
   "source": [
    "### Visualization of images\n",
    "Let's visualize the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3485223d40941ab326c76d364bc1136a566e7749"
   },
   "outputs": [],
   "source": [
    "for filename in img_files[:3]:\n",
    "    img=mpimg.imread(filename)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img, cmap ='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b371aecb3ff7e314201fd45ed31136c942a4d52c"
   },
   "source": [
    "Good to observe that there are no categorical data. So, normalisation is done using label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "efb470a284b84af0b541780aa953396382b9b9a7"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(img_targets)\n",
    "encoded_Y = encoder.transform(img_targets)\n",
    "\n",
    "print(img_files[:5], img_targets[:5], encoded_Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d4c0e0f902db4f78da7b89505059b74e3ed75887"
   },
   "source": [
    "Splitting of data into training and validation sets for cross validation with 4:1:1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd0cad3ba7235ad7392c9ef22240bf32d33d4d43"
   },
   "outputs": [],
   "source": [
    "train_files, rem_files, train_targets, rem_targets = train_test_split(\n",
    "        img_files, encoded_Y, train_size=0.66, random_state=52, shuffle= True)\n",
    "\n",
    "validation_files, test_files, validation_targets, test_targets = train_test_split(\n",
    "        rem_files, rem_targets, train_size=0.5, random_state=22, shuffle=True)\n",
    "\n",
    "print(train_files.shape, validation_files.shape, test_files.shape)\n",
    "print(train_targets.shape, validation_targets.shape, test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4129fb056d957a234bb1d548e37624bb104c6bd3"
   },
   "source": [
    "### Input to the model\n",
    "\n",
    "As said before, we take patches of data, each of size 113x133. A generator function is implemented for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac174996e85c0cc34466494c032d4ccd66768c69",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator function for generating random crops from each sentence\n",
    "\n",
    "# # Now create generators for randomly cropping 113x113 patches from these images\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 50\n",
    "\n",
    "# Start with train generator shared in the class and add image augmentations\n",
    "def generate_data(samples, target_files,  batch_size=batch_size, factor = 0.1 ):\n",
    "    num_samples = len(samples)\n",
    "    from sklearn.utils import shuffle\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            batch_targets = target_files[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            targets = []\n",
    "            for i in range(len(batch_samples)):\n",
    "                batch_sample = batch_samples[i]\n",
    "                batch_target = batch_targets[i]\n",
    "                im = Image.open(batch_sample)\n",
    "                cur_width = im.size[0]\n",
    "                cur_height = im.size[1]\n",
    "\n",
    "                # print(cur_width, cur_height)\n",
    "                height_fac = 113 / cur_height\n",
    "\n",
    "                new_width = int(cur_width * height_fac)\n",
    "                size = new_width, 113\n",
    "\n",
    "                imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n",
    "                now_width = imresize.size[0]\n",
    "                now_height = imresize.size[1]\n",
    "                # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n",
    "\n",
    "                avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n",
    "\n",
    "                # Pick random x%\n",
    "                pick_num = int(len(avail_x_points)*factor)\n",
    "\n",
    "                # Now pick\n",
    "                random_startx = sample(avail_x_points,  pick_num)\n",
    "\n",
    "                for start in random_startx:\n",
    "                    imcrop = imresize.crop((start, 0, start+113, 113))\n",
    "                    images.append(np.asarray(imcrop))\n",
    "                    targets.append(batch_target)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(targets)\n",
    "\n",
    "            #reshape X_train for feeding in later\n",
    "            X_train = X_train.reshape(X_train.shape[0], 113, 113, 1)\n",
    "            #convert to float and normalize\n",
    "            X_train = X_train.astype('float32')\n",
    "            X_train /= 255\n",
    "\n",
    "            #One hot encode y\n",
    "            y_train = to_categorical(y_train, num_classes)\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d5c49f71f30de1bf86253d44afe5cef879ed1c3"
   },
   "source": [
    "For training and testing,  generator function is called with the intent of making train and test generator data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e1b1e517cb2db59aaf6ecabdc62b553057b9bdd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = generate_data(train_files, train_targets, batch_size=batch_size, factor = 0.3)\n",
    "validation_generator = generate_data(validation_files, validation_targets, batch_size=batch_size, factor = 0.3)\n",
    "test_generator = generate_data(test_files, test_targets, batch_size=batch_size, factor = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95ff8485f8b8c9ecaacd4fdf1d618dac98be0e1c"
   },
   "source": [
    "A Keras Model is built. Summary of the model is printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0eadd72c9a88c06049746d9e8bd1b82931eafa82"
   },
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    import tensorflow as tf\n",
    "    return tf.image.resize_images(image,[56,56])\n",
    "\n",
    "# Function to resize image to 64x64\n",
    "row, col, ch = 113, 113, 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(row, col, ch)))\n",
    "\n",
    "# Resise data within the neural network\n",
    "model.add(Lambda(resize_image))  #resize images to allow for easy computation\n",
    "\n",
    "# CNN model - Building the model suggested in paper\n",
    "\n",
    "model.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2,2), padding='same', name='conv1')) #96\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool1'))\n",
    "\n",
    "model.add(Convolution2D(filters= 64, kernel_size =(3,3), strides= (1,1), padding='same', name='conv2'))  #256\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool2'))\n",
    "\n",
    "model.add(Convolution2D(filters= 128, kernel_size =(3,3), strides= (1,1), padding='same', name='conv3'))  #256\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool3'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, name='dense1'))  #1024\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, name='dense2'))  #1024\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes,name='output'))\n",
    "model.add(Activation('softmax'))  #softmax since output is within 50 classes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7a4f8de3dd87584c52e407c774f22d731bd00de"
   },
   "source": [
    "### Training the model\n",
    "\n",
    "Let's take 8 epochs. And the following specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be9bb7360d3cfc14cdc2a5df5ad47defd05776e3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nb_epoch = 8\n",
    "\n",
    "# samples_per_epoch = 3268\n",
    "# nb_val_samples = 842\n",
    "\n",
    "\n",
    "# #save every model using Keras checkpoint\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# filepath=\"checkpoint2/check-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath= filepath, verbose=1, save_best_only=False)\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# #Model fit generator\n",
    "# history_object = model.fit_generator(train_generator, samples_per_epoch= samples_per_epoch,\n",
    "#                                      validation_data=validation_generator,\n",
    "#                                      nb_val_samples=nb_val_samples, nb_epoch=nb_epoch, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be385264509ecce0061864f0f30f0c95e49e4474"
   },
   "source": [
    "### Performance Metrics\n",
    "\n",
    "Let's now test our model for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "921e6244c1ebeb7ccac680503c0987936a42aace",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('low_loss.hdf5')\n",
    "# scores = model.evaluate_generator(test_generator,842) \n",
    "# print(\"Accuracy = \", scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b599a7eca29767294208f579b757fcbe12ded7d"
   },
   "source": [
    "Load in test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56f8b903170d0f4d7d496ace5f2954141d5a7e81",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images = []\n",
    "# for filename in test_files[:50]:\n",
    "#     im = Image.open(filename)\n",
    "#     cur_width = im.size[0]\n",
    "#     cur_height = im.size[1]\n",
    "\n",
    "#     # print(cur_width, cur_height)\n",
    "#     height_fac = 113 / cur_height\n",
    "\n",
    "#     new_width = int(cur_width * height_fac)\n",
    "#     size = new_width, 113\n",
    "\n",
    "#     imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n",
    "#     now_width = imresize.size[0]\n",
    "#     now_height = imresize.size[1]\n",
    "#     # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n",
    "\n",
    "#     avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n",
    "\n",
    "#     # Pick random x%\n",
    "#     factor = 0.1\n",
    "#     pick_num = int(len(avail_x_points)*factor)\n",
    "    \n",
    "#     random_startx = sample(avail_x_points,  pick_num)\n",
    "\n",
    "#     for start in random_startx:\n",
    "#         imcrop = imresize.crop((start, 0, start+113, 113))\n",
    "#         images.append(np.asarray(imcrop))\n",
    "        \n",
    "#     X_test = np.array(images)\n",
    "    \n",
    "#     X_test = X_test.reshape(X_test.shape[0], 113, 113, 1)\n",
    "#     #convert to float and normalize\n",
    "#     X_test = X_test.astype('float32')\n",
    "#     X_test /= 255\n",
    "#     shuffle(X_test)\n",
    "\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c69d84dcc9a5a5df52f441d444bf3d64cbeb3ac5"
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0458779a20d43667eb416904ddff447b49282124",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_test, verbose =1)\n",
    "\n",
    "# print(predictions.shape)\n",
    "# predicted_writer = []\n",
    "# for pred in predictions:\n",
    "#     predicted_writer.append(np.argmax(pred))\n",
    "# print(len(predicted_writer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "12f114167ec93e64f4ef3901b544df40ca8aeb67"
   },
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5da1e6b4bc0c262002a99f590c8f993dcd3780ea",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer_number = 18\n",
    "# total_images =10\n",
    "# counter = 0\n",
    "# for i in range(len(predicted_writer)//10):\n",
    "#     if predicted_writer[i] == writer_number:\n",
    "#         image = X_test[i].squeeze()\n",
    "#         plt.figure(figsize=(2,2))\n",
    "#         plt.imshow(image, cmap ='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
